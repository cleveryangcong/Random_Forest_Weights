{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf1332d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path setup\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"/home/dchen/Random_Forest_Weights/\")\n",
    "\n",
    "# Basics:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Helpful:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Pipeline and ColumnsTransformer:\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "# models:\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# my functions:\n",
    "from src_rf.methods.calc_mean import *\n",
    "from src_rf.methods.calc_weights import *\n",
    "from src_rf.methods.calc_dist import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d140a870",
   "metadata": {},
   "source": [
    "### 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d414423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/dchen/Random_Forest_Weights/src_rf/data/energy_data_hourly.csv\"\n",
    "                 , index_col = 'datetime', parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a633b1c",
   "metadata": {},
   "source": [
    "### 2. Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "483271a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('total_energy_usage', axis = 1)\n",
    "y = df['total_energy_usage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e9c7c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3 ,shuffle=False, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cec854d",
   "metadata": {},
   "source": [
    "### 2. Load Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e8cb5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.sparse import load_npz\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "def load_sparse_matrices_from_dir(dir_path):\n",
    "    \"\"\"Load all sparse matrices from a directory.\"\"\"\n",
    "    tree_files = sorted([os.path.join(dir_path, file) for file in os.listdir(dir_path)])\n",
    "    return [load_npz(file) for file in tree_files]\n",
    "\n",
    "def load_all_rf_weights(base_dir, num_batches, num_trees):\n",
    "    \"\"\"Load and combine all rf weights.\"\"\"\n",
    "    all_rf_weights = [[] for _ in range(num_trees)]\n",
    "\n",
    "    for batch_idx in range(num_batches):\n",
    "        batch_dir = os.path.join(base_dir, f\"batch_{batch_idx}\")\n",
    "        batch_weights = load_sparse_matrices_from_dir(batch_dir)\n",
    "\n",
    "        for tree_idx, weights in enumerate(batch_weights):\n",
    "            all_rf_weights[tree_idx].append(weights)\n",
    "\n",
    "    # Now concatenate all batches for each tree\n",
    "    for tree_idx in range(num_trees):\n",
    "        all_rf_weights[tree_idx] = vstack(all_rf_weights[tree_idx])\n",
    "\n",
    "    return all_rf_weights\n",
    "\n",
    "# Before the Usage section:\n",
    "batch_size = 500  # This was the batch size you've defined earlier\n",
    "df = pd.read_csv(\"/home/dchen/Random_Forest_Weights/src_rf/data/energy_data_hourly.csv\", index_col=\"datetime\")\n",
    "X = df.drop('total_energy_usage', axis=1).values\n",
    "_, X_test, _, _ = train_test_split(X, y, test_size=0.3, shuffle=False, random_state=42)\n",
    "num_samples = X_test.shape[0]\n",
    "\n",
    "# Usage\n",
    "base_dir = \"/Data/Delong_BA_Data/rf_weights/\"\n",
    "num_batches = (num_samples + batch_size - 1) // batch_size  # ceiling division to find number of batches\n",
    "# num_batches = 2\n",
    "num_trees = 300  # based on your RandomForestRegressor setup\n",
    "\n",
    "rf_weights_loaded = load_all_rf_weights(base_dir, num_batches, num_trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3198df",
   "metadata": {},
   "source": [
    "### 3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8349636c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=40.0, max_samples=0.5, min_samples_leaf=5,\n",
       "                      min_samples_split=5, n_estimators=300, n_jobs=-1,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.1 Parameters for Weight_Calculation:\n",
    "bootstrap = True\n",
    "max_samples = 0.5\n",
    "# 3.2 Parameters for RF\n",
    "n_estimators = 300\n",
    "min_samples_split = 5\n",
    "min_samples_leaf = 5\n",
    "max_depth = 40.0\n",
    "\n",
    "# 3.3 Model Training\n",
    "rf = RandomForestRegressor(\n",
    "    bootstrap=bootstrap, max_samples=max_samples,n_estimators = n_estimators, min_samples_split = min_samples_split, min_samples_leaf = min_samples_leaf, max_depth = max_depth, verbose=0, n_jobs=-1, random_state = 42\n",
    ")\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c565454e",
   "metadata": {},
   "source": [
    "### 4. Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a19fc4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rf_weights_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "999446c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rf_weights_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "988d661e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(rf_weights_loaded[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ede0f54d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_mean_weights = calc_mean_rf(rf_weights_loaded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd84cdcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_mean_weights = calc_mean_rf(rf_weights_loaded, y_train)\n",
    "rf_mean_normal = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d013165",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20456"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are the two the same?\n",
    "sum(np.round(rf_mean_weights, 5) == np.round(rf_mean_normal[0:rf_weights_loaded[0].shape[0]], 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a14e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0296bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6fbf38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5adb4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d55af84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
